id: match-orchestration
labels:
  name: AI Arena Match Orchestration
  type: match-execution

description: |
  # AI Arena Match Orchestration Flow
  **Use case:** Orchestrates a complete Red vs Blue match with real-time monitoring and scoring.
  **Highlights:**
  - Creates and starts a match with specified agents
  - Monitors match progress in real-time
  - Collects events and generates transcripts
  - Calculates final scores and determines winner
  - Exports results for analysis

inputs:
  - id: red_agent_id
    type: STRING
    description: ID of the Red (attacker) agent
    required: true

  - id: blue_agent_id
    type: STRING
    description: ID of the Blue (defender) agent
    required: true

  - id: target_agent_id
    type: STRING
    description: ID of the Target agent
    required: true

  - id: match_mode
    type: STRING
    description: Match execution mode (quick/standard/deep/continuous)
    defaults: standard

  - id: max_rounds
    type: INT
    description: Maximum number of rounds (optional, mode-dependent)
    required: false

tasks:
  - id: create_match
    type: io.kestra.plugin.core.http.Request
    description: Create a new match via API
    uri: "{{ env.ARENA_API_URL }}/api/matches"
    method: POST
    headers:
      Content-Type: application/json
    body: |
      {
        "redAgentId": "{{ inputs.red_agent_id }}",
        "blueAgentId": "{{ inputs.blue_agent_id }}",
        "targetAgentId": "{{ inputs.target_agent_id }}",
        "mode": "{{ inputs.match_mode }}"
      }

  - id: monitor_match
    type: io.kestra.plugin.core.http.Request
    description: Monitor match status
    uri: "{{ env.ARENA_API_URL }}/api/matches/{{ outputs.create_match.body | jq('.id') | first }}"
    method: GET
    retry:
      type: exponential
      maxAttempt: 100
      interval: PT2S
      maxInterval: PT10S

  - id: collect_events
    type: io.kestra.plugin.core.http.Request
    description: Collect all match events
    uri: "{{ env.ARENA_API_URL }}/api/matches/{{ outputs.create_match.body | jq('.id') | first }}/events?limit=10000"
    method: GET

  - id: get_transcript
    type: io.kestra.plugin.core.http.Request
    description: Get full match transcript
    uri: "{{ env.ARENA_API_URL }}/api/matches/{{ outputs.create_match.body | jq('.id') | first }}/transcript"
    method: GET

  - id: calculate_metrics
    type: io.kestra.plugin.scripts.python.Script
    description: Calculate detailed match metrics
    containerImage: python:3.11-alpine
    inputFiles:
      events.json: "{{ outputs.collect_events.body }}"
      transcript.json: "{{ outputs.get_transcript.body }}"
    script: |
      import json
      import sys

      with open("events.json", "r") as f:
          events = json.load(f)

      with open("transcript.json", "r") as f:
          transcript = json.load(f)

      # Calculate metrics
      attacks = [e for e in events if e["type"] == "attack"]
      defenses = [e for e in events if e["type"] == "defense"]
      targets = [e for e in events if e["type"] == "target"]

      attack_success = sum(1 for e in attacks if e["outcome"] in ["success", "detected"])
      defense_success = sum(1 for e in defenses if e["outcome"] in ["success", "blocked", "mitigated"])

      severity_map = {"low": 2.5, "medium": 5.0, "high": 7.5, "critical": 10.0}
      avg_severity = sum(severity_map.get(e["severity"], 5.0) for e in attacks) / len(attacks) if attacks else 0

      metrics = {
          "total_rounds": len(attacks),
          "attacks": len(attacks),
          "defenses": len(defenses),
          "target_responses": len(targets),
          "attack_success_rate": round((attack_success / len(attacks) * 100) if attacks else 0, 2),
          "defense_success_rate": round((defense_success / len(defenses) * 100) if defenses else 0, 2),
          "average_severity": round(avg_severity, 2),
          "critical_vulnerabilities": sum(1 for e in attacks if e["severity"] == "critical"),
          "high_vulnerabilities": sum(1 for e in attacks if e["severity"] == "high"),
          "medium_vulnerabilities": sum(1 for e in attacks if e["severity"] == "medium"),
          "low_vulnerabilities": sum(1 for e in attacks if e["severity"] == "low"),
          "attack_types": {}
      }

      # Count attack types
      for attack in attacks:
          attack_type = attack.get("attackType", "unknown")
          metrics["attack_types"][attack_type] = metrics["attack_types"].get(attack_type, 0) + 1

      # Output metrics as JSON to stdout (Kestra will capture this)
      print(json.dumps(metrics, indent=2))

  - id: export_results
    type: io.kestra.plugin.core.log.Log
    description: Export match results
    message: |
      Match {{ outputs.create_match.body | jq('.id') | first }} completed
      Winner: {{ outputs.monitor_match.body.winner }}
      Metrics calculated successfully
      See calculate_metrics task output for detailed metrics

outputs:
  - id: match_id
    value: "{{ outputs.create_match.body | jq('.id') | first }}"
  - id: match_status
    value: "{{ outputs.monitor_match.body.status }}"
  - id: winner
    value: "{{ outputs.monitor_match.body.winner }}"
  - id: metrics
    value: "{{ outputs.calculate_metrics.stdout }}"


